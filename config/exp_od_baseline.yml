context:
  experiment_set: od
  experiment_name: baseline
  artifactory_root: ./artifactory
  execution_type: training
  verbose: 2

model:
  input_width: 320
  input_height: 200
  maximum_stride: 8
  backbone_spec:
    name: SmallFCNN
    stage_type: simple  # residual
    width_base: 32
    strides: [8]
  neck_spec:
    name: Rescaler
    output_stride: 4
  head_spec:
    name: OD
    num_classes: 16
    peak_nms: 0.1

training:
  data:
    - name: cocodoom
      root: /data/Datasets/cocodoom
      subset: train
      sampling_probability: 1.0
      filtered_map_numbers: []
      filtered_num_objects: 1
      transformations:
        - { name: image, stride: 1 }
        - { name: uniform_heatmap, stride: 4 }
        - { name: regression, stride: 4 }
      kwargs:
        full: False
        split: run
  epochs: 120
  steps_per_epoch: 500
  batch_size: 10
  criteria_spec:
    name: ctdet_od
  optimizer_spec:
    name: Adam
  lr_schedule_spec:
    name: PiecewiseConstantDecay
    boundaries: [1500]
    values: [0.001, 0.0001]
  callbacks:
    - { name: LatestModelCheckpoint }
    - { name: ObjectMAP, checkpoint_best: True }
    - { name: CSVLogger }
    - { name: TensorBoard }

evaluation:
  data:
    - name: cocodoom
      root: /data/Datasets/cocodoom
      subset: val-mini
      filtered_map_numbers: []
      transformations:
        - { name: image, stride: 1 }
      kwargs:
        full: False
        split: run
  detection_output_file : default

inference:
  data:
    - name: cocodoom
      root: /data/Datasets/cocodoom
      subset: val
      filtered_map_numbers: [ 1, 2 ]
      transformations:
        - { name: image, stride: 1 }
      kwargs:
        full: True
        split: run

  visualization_mode: detection
  to_screen: True
  output_video_path: None
  fps: 25
  total_num_frames: 200
